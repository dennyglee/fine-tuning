{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aa5c3bf1-cfe1-4059-b163-47766c785f57",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Introduction\n",
    "The [t5-small on a single GPU](1. T5-Small on Single GPU) example provided a straightforward example of fine-tuning a language model. However, you might have noticed that the training problem was still essentially structured as a supervised learning problem: we had a text (code snippet) and a desired completion. When training LLMs like the GPT models, labels are not provided manually. We instead use an approach called self-supervised learning wherein the objective is automatically computed from the inputs. One example of self-supervised learning is causal language modeling, where the task is to predict the next word based on the previous words. E.g. the sentence \"The boy hid behind the tree\" would be decomposed into the following training tasks:\n",
    "- Input: `The`, Target: `boy`\n",
    "- Input: `The boy`, Target: `hid`\n",
    "- Input: `The boy hid`, Target: `behind`\n",
    "- Input: `The boy hid behind`, Target: `the`\n",
    "- Input: `The boy hid behind the`, Target: `tree`.\n",
    "\n",
    "This requires us to preprocess our data and pass it along to the model somewhat differently, which will be the subject of this notebook. We will still limit this example to training on a single GPU (an a10 with 24GB VRAM). We will use the [gpt2](https://huggingface.co/gpt2) model with 124M parameters. Recalling the heuristic that training requires VRAM in GB ≥ 16 times the number of parameters in billions, we require .124 * 16 ≅ 2GB VRAM, so we should not be VRAM constrained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bd5b52a8-0cc1-487b-84d1-59c3873fc768",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "2. GPT2 on a single GPU",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
